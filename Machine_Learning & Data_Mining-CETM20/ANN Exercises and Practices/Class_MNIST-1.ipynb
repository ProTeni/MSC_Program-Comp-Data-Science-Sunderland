{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a04bd5",
   "metadata": {},
   "source": [
    "# Classifcation on hand writen numbers\n",
    "\n",
    "In this activity we will be using MNIST dataset: \n",
    "https://www.tensorflow.org/datasets/catalog/mnist\n",
    "\n",
    "To develop a classifer of hand writen numbers as shown in the following figure\n",
    "\n",
    "<div>\n",
    "<img src=\"attachment:image.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "This activity is modiffied from https://keras.io/examples/vision/mnist_convnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651e20b",
   "metadata": {},
   "source": [
    "\n",
    "# Title: Simple MNIST convnet\n",
    "\n",
    "# Description: A simple convnet that achieves ~99% test accuracy on MNIST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72d140",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b3d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a06b9",
   "metadata": {},
   "source": [
    "# **Prepare the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be04a2d",
   "metadata": {},
   "source": [
    "**Model / data parameters**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fa4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1604d",
   "metadata": {},
   "source": [
    "**the data, split between train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a98877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bb394",
   "metadata": {},
   "source": [
    "**Scale images to the [0, 1] range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a438ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfed6c4",
   "metadata": {},
   "source": [
    "**Make sure images have shape (28, 28, 1)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae1faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912b33a",
   "metadata": {},
   "source": [
    "1 channel always reers to blanck and white (the gray scale which nis either black, a combination or the black and white or white)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48211bc",
   "metadata": {},
   "source": [
    "**convert class vectors to binary class matrices**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2c72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee93a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], shape=(60000, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fcacb",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c060712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m16,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56337d",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc22ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.8949 - loss: 0.3525 - val_accuracy: 0.9780 - val_loss: 0.0781\n",
      "Epoch 2/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.9678 - loss: 0.1067 - val_accuracy: 0.9832 - val_loss: 0.0566\n",
      "Epoch 3/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 56ms/step - accuracy: 0.9746 - loss: 0.0826 - val_accuracy: 0.9872 - val_loss: 0.0454\n",
      "Epoch 4/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 53ms/step - accuracy: 0.9784 - loss: 0.0695 - val_accuracy: 0.9888 - val_loss: 0.0385\n",
      "Epoch 5/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9803 - loss: 0.0615 - val_accuracy: 0.9897 - val_loss: 0.0372\n",
      "Epoch 6/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9830 - loss: 0.0546 - val_accuracy: 0.9900 - val_loss: 0.0357\n",
      "Epoch 7/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9841 - loss: 0.0512 - val_accuracy: 0.9910 - val_loss: 0.0350\n",
      "Epoch 8/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.9853 - loss: 0.0474 - val_accuracy: 0.9910 - val_loss: 0.0322\n",
      "Epoch 9/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 56ms/step - accuracy: 0.9860 - loss: 0.0452 - val_accuracy: 0.9915 - val_loss: 0.0322\n",
      "Epoch 10/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 68ms/step - accuracy: 0.9867 - loss: 0.0420 - val_accuracy: 0.9907 - val_loss: 0.0343\n",
      "Epoch 11/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 58ms/step - accuracy: 0.9872 - loss: 0.0395 - val_accuracy: 0.9913 - val_loss: 0.0295\n",
      "Epoch 12/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 64ms/step - accuracy: 0.9884 - loss: 0.0371 - val_accuracy: 0.9915 - val_loss: 0.0315\n",
      "Epoch 13/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 55ms/step - accuracy: 0.9885 - loss: 0.0364 - val_accuracy: 0.9912 - val_loss: 0.0310\n",
      "Epoch 14/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 74ms/step - accuracy: 0.9884 - loss: 0.0362 - val_accuracy: 0.9903 - val_loss: 0.0297\n",
      "Epoch 15/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 57ms/step - accuracy: 0.9888 - loss: 0.0342 - val_accuracy: 0.9920 - val_loss: 0.0286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x217bec28f70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549d580",
   "metadata": {},
   "source": [
    "# Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d27cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.025071822106838226\n",
      "Test accuracy: 0.9918000102043152\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0163ad",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "HyperParameter Optimization with Keras.Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "798aa1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement KerasTuner (from versions: none)\n",
      "ERROR: No matching distribution found for KerasTuner\n"
     ]
    }
   ],
   "source": [
    "pip install KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "003e69b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab281db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.InputLayer(input_shape=(28,28,1)))\n",
    "\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv1_filters', 32, 128, step=32),\n",
    "        kernel_size=hp.choice('conv1_kernel', [3,5]),\n",
    "        activation='relu'\n",
    "        #,padding='same'\n",
    "    ))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv2_filters', 64, 256, step=32),\n",
    "        kernel_size=hp.choice('conv2_kernel', [3,5]),\n",
    "        activation='relu'\n",
    "        #,padding='same'\n",
    "    ))\n",
    "\n",
    " \n",
    "    if hp.Boolean('add_conv3'):\n",
    "        model.add(layers.Conv2D(\n",
    "            filters=hp.Int('conv3_filters', 32, 256, step=32),\n",
    "            kernel_size=hp.choice('conv3_kernel', [3,3]),\n",
    "            activation=hp.choice('activation', ['relu', 'tanh', 'leaky_relu'])\n",
    "        ))\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "        if hp.Boolean('add_conv4'):\n",
    "            model.add(layers.Conv2D(\n",
    "                filters=hp.Int('conv4_filters',64, 128,step=32),\n",
    "                kernel_size = hp.choice('conv4_kernel', [5,5]),\n",
    "                activation=hp.choice('activation', ['relu', 'tanh', 'leaky_relu'])\n",
    "                        ))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "    if hp.Boolean('add_dense'):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int('dense_units', 128, 512, step=64),\n",
    "            activation='relu'\n",
    "        ))\n",
    "\n",
    "    model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv1_filters', 32, 128, step=32),\n",
    "        kernel_size=hp.Choice('conv1_kernel', [3, 5]),\n",
    "        activation=hp.Choice('activation1', ['relu', 'tanh', 'leaky_relu']),\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv2_filters', 64, 256, step=32),\n",
    "        kernel_size=hp.Choice('conv2_kernel', [3, 5]),\n",
    "        activation=hp.Choice('activation2', ['relu', 'tanh', 'leaky_relu']),\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense_units', 128, 512, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96234e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_improved_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # === INPUT LAYER ===\n",
    "    model.add(layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "    \n",
    "    # === CONV BLOCK 1 ===\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv1_filters', 32, 128, step=32),  # 32, 64, 96, 128\n",
    "        kernel_size=hp.Choice('conv1_kernel', [3, 5]),      # Must be hp.Choice (not hp.choice)\n",
    "        activation='relu',\n",
    "        padding='same'  # ← ADDED: Preserves spatial dimensions\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(2))  # Reduces 28x28 → 14x14\n",
    "    \n",
    "    # === CONV BLOCK 2 ===  \n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv2_filters', 64, 256, step=64),  # 64, 128, 192, 256\n",
    "        kernel_size=hp.Choice('conv2_kernel', [3, 5]),\n",
    "        activation='relu',\n",
    "        padding='same'  # ← ADDED\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(2))  # Reduces 14x14 → 7x7\n",
    "    \n",
    "    # === OPTIONAL DEEPER CONV BLOCKS ===\n",
    "    if hp.Boolean('add_conv3'):\n",
    "        model.add(layers.Conv2D(\n",
    "            filters=hp.Int('conv3_filters', 128, 512, step=64),\n",
    "            kernel_size=hp.Choice('conv3_kernel', [3, 5]),\n",
    "            activation=hp.Choice('conv3_activation', ['relu', 'tanh', 'leaky_relu']),\n",
    "            padding='same'\n",
    "        ))\n",
    "        # Optional pooling for conv3\n",
    "        if hp.Boolean('add_pool_after_conv3'):\n",
    "            model.add(layers.MaxPooling2D(2))  # Reduces 7x7 → 3x3 (careful!)\n",
    "    \n",
    "    # === FLATTEN ===\n",
    "    model.add(layers.Flatten())  # Converts 2D → 1D for dense layers\n",
    "    \n",
    "    # === DROPOUT FOR REGULARIZATION ===\n",
    "    model.add(layers.Dropout(\n",
    "        rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)  # 0.2, 0.3, 0.4, 0.5\n",
    "    ))\n",
    "    \n",
    "    # === OPTIONAL DENSE LAYER ===\n",
    "    if hp.Boolean('add_dense'):  # ← FIXED NAME from 'add_conv5'\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int('dense_units', 128, 512, step=64),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        # Additional dropout for dense layer\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float('dense_dropout', 0.1, 0.4, step=0.1)\n",
    "        ))\n",
    "    \n",
    "    # === OUTPUT LAYER ===\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # === COMPILE WITH TUNABLE LEARNING RATE ===\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "        ),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc204fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.0591 - val_accuracy: 0.9883 - val_loss: 0.0329\n",
      "Epoch 2/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0486 - val_accuracy: 0.9907 - val_loss: 0.0294\n",
      "Epoch 3/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0456 - val_accuracy: 0.9903 - val_loss: 0.0295\n",
      "Epoch 4/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.0408 - val_accuracy: 0.9915 - val_loss: 0.0274\n",
      "Epoch 5/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 12ms/step - accuracy: 0.9879 - loss: 0.0372 - val_accuracy: 0.9908 - val_loss: 0.0291\n",
      "Epoch 6/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0364 - val_accuracy: 0.9908 - val_loss: 0.0292\n",
      "Epoch 7/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0343 - val_accuracy: 0.9917 - val_loss: 0.0305\n",
      "Epoch 8/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.0333 - val_accuracy: 0.9913 - val_loss: 0.0278\n",
      "Epoch 9/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0319 - val_accuracy: 0.9917 - val_loss: 0.0254\n",
      "Epoch 10/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0292 - val_accuracy: 0.9915 - val_loss: 0.0278\n",
      "Epoch 11/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0284 - val_accuracy: 0.9928 - val_loss: 0.0272\n",
      "Epoch 12/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0282 - val_accuracy: 0.9912 - val_loss: 0.0310\n",
      "Epoch 13/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0285 - val_accuracy: 0.9905 - val_loss: 0.0337\n",
      "Epoch 14/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0250 - val_accuracy: 0.9913 - val_loss: 0.0302\n",
      "Epoch 15/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0255 - val_accuracy: 0.9918 - val_loss: 0.0292\n",
      "Epoch 16/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0256 - val_accuracy: 0.9927 - val_loss: 0.0281\n",
      "Epoch 17/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 12ms/step - accuracy: 0.9922 - loss: 0.0246 - val_accuracy: 0.9908 - val_loss: 0.0304\n",
      "Epoch 18/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0262 - val_accuracy: 0.9915 - val_loss: 0.0310\n",
      "Epoch 19/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0250 - val_accuracy: 0.9922 - val_loss: 0.0291\n",
      "Epoch 20/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0240 - val_accuracy: 0.9925 - val_loss: 0.0319\n",
      "Epoch 21/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0231 - val_accuracy: 0.9913 - val_loss: 0.0351\n",
      "Epoch 22/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0227 - val_accuracy: 0.9918 - val_loss: 0.0341\n",
      "Epoch 23/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 12ms/step - accuracy: 0.9934 - loss: 0.0207 - val_accuracy: 0.9903 - val_loss: 0.0401\n",
      "Epoch 24/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0232 - val_accuracy: 0.9918 - val_loss: 0.0272\n",
      "Epoch 25/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0222 - val_accuracy: 0.9917 - val_loss: 0.0300\n",
      "Epoch 26/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0216 - val_accuracy: 0.9913 - val_loss: 0.0333\n",
      "Epoch 27/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0207 - val_accuracy: 0.9913 - val_loss: 0.0389\n",
      "Epoch 28/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.9913 - val_loss: 0.0347\n",
      "Epoch 29/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0193 - val_accuracy: 0.9925 - val_loss: 0.0363\n",
      "Epoch 30/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.9908 - val_loss: 0.0334\n",
      "Epoch 31/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0198 - val_accuracy: 0.9922 - val_loss: 0.0359\n",
      "Epoch 32/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0200 - val_accuracy: 0.9925 - val_loss: 0.0348\n",
      "Epoch 33/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0185 - val_accuracy: 0.9918 - val_loss: 0.0375\n",
      "Epoch 34/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0196 - val_accuracy: 0.9908 - val_loss: 0.0409\n",
      "Epoch 35/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 0.0184 - val_accuracy: 0.9920 - val_loss: 0.0389\n",
      "Epoch 36/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 13ms/step - accuracy: 0.9934 - loss: 0.0210 - val_accuracy: 0.9917 - val_loss: 0.0392\n",
      "Epoch 37/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18ms/step - accuracy: 0.9933 - loss: 0.0210 - val_accuracy: 0.9920 - val_loss: 0.0336\n",
      "Epoch 38/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0190 - val_accuracy: 0.9927 - val_loss: 0.0379\n",
      "Epoch 39/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0166 - val_accuracy: 0.9892 - val_loss: 0.0471\n",
      "Epoch 40/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0196 - val_accuracy: 0.9927 - val_loss: 0.0405\n",
      "Epoch 41/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0191 - val_accuracy: 0.9898 - val_loss: 0.0467\n",
      "Epoch 42/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0197 - val_accuracy: 0.9922 - val_loss: 0.0367\n",
      "Epoch 43/100\n",
      "\u001b[1m5400/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.9908 - val_loss: 0.0431\n",
      "Epoch 44/100\n",
      "\u001b[1m4504/5400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0164"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#loop through a lits for epoch and batchsize\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kojus\\anaconda3\\envs\\ML_DM\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kojus\\anaconda3\\envs\\ML_DM\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\kojus\\anaconda3\\envs\\ML_DM\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:221\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m ):\n\u001b[0;32m    220\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[1;32mc:\\Users\\kojus\\anaconda3\\envs\\ML_DM\\lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kojus\\anaconda3\\envs\\ML_DM\\lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[1;34m(optional, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_final, X_val, y_train_final, y_val =train_test_split(x_train, y_train,test_size=0.1, random_state=2, stratify=y_train)\n",
    "\n",
    "\n",
    "\n",
    "#loop through a lits for epoch and batchsize\n",
    "\n",
    "model.fit(x_train_final, y_train_final,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=100,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de64db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR\n",
    "\n",
    "#from sklearn.utils import shuffle\n",
    "#x_train, y_train = shuffle(x_train, y_train, random_state=2)\n",
    "\n",
    "#model.fit(x_train, y_train, validation_split=0.1, epochs=15)\n",
    "\n",
    "#suflle is necessary here if the vlaidation-split will be used instead of train-test-split to ensure the classes are well shiffled and the val datset isnt the LAST 10 samples. \n",
    "#But random 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f238061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "175af561",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### Why does `input_shape` have (28, 28, 1)?\n",
    "\n",
    "- **28, 28:**  \n",
    "  The MNIST dataset images are **28 pixels wide** and **28 pixels tall**.  \n",
    "  Each image is a small square (28x28 grid).\n",
    "\n",
    "- **1:**  \n",
    "  The last dimension is the **number of channels**.  \n",
    "  For MNIST, images are **grayscale** (not color), so there is **1 channel**.\n",
    "\n",
    "**Summary:**  \n",
    "`input_shape = (28, 28, 1)` means each input image is 28x28 pixels, with 1 grayscale channel.\n",
    "\n",
    "---\n",
    "\n",
    "### Why divide by 255?\n",
    "\n",
    "- **Pixel values in MNIST:**  \n",
    "  Each pixel is an integer between **0** (black) and **255** (white).\n",
    "- **Dividing by 255:**  \n",
    "  Converts pixel values to the range **[0, 1]** (float), which helps neural networks train better and faster.\n",
    "\n",
    "**Example:**  \n",
    "A pixel value of 128 becomes `128 / 255 ≈ 0.502`.\n",
    "\n",
    "---\n",
    "\n",
    "### What does grayscale mean?\n",
    "\n",
    "- **Grayscale image:**  \n",
    "  Each pixel represents only **brightness** (no color).\n",
    "  - 0 = black\n",
    "  - 255 = white\n",
    "  - Values in between = shades of gray\n",
    "\n",
    "- **Color image:**  \n",
    "  Has **3 channels** (Red, Green, Blue), e.g. `(28, 28, 3)`.\n",
    "\n",
    "---\n",
    "\n",
    "### What does \"1 channel\" mean?\n",
    "\n",
    "- **Channel:**  \n",
    "  Represents a layer of information for each pixel.\n",
    "- **1 channel:**  \n",
    "  Only brightness (grayscale).\n",
    "- **3 channels:**  \n",
    "  RGB color (each pixel has 3 values).\n",
    "\n",
    "**In MNIST:**  \n",
    "- Each image is `(28, 28, 1)` → 28x28 pixels, 1 value per pixel (grayscale).\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table:**\n",
    "\n",
    "| Shape           | Meaning                        |\n",
    "|-----------------|-------------------------------|\n",
    "| (28, 28, 1)     | 28x28 pixels, grayscale image |\n",
    "| (28, 28, 3)     | 28x28 pixels, RGB color image |\n",
    "\n",
    "Let me know if you want a visual example or code!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
